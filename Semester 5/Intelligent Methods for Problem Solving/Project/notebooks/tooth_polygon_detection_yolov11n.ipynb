{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ItNTObdkVmw",
        "outputId": "1f12965b-d4a0-4ebc-84e4-a8cb9061d122"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.58-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.58-py3-none-any.whl (905 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m905.3/905.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.58 ultralytics-thop-2.0.13\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6Ow1C-plzi_",
        "outputId": "c5b932ef-51ad-4f4a-b2be-a84140d45361"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K\r\u001b[2K\rUltralytics 8.3.58 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 33.4/112.6 GB disk)\n",
            "\n",
            "OS                  Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "Environment         Colab\n",
            "Python              3.10.12\n",
            "Install             pip\n",
            "RAM                 12.67 GB\n",
            "Disk                33.4/112.6 GB\n",
            "CPU                 Intel Xeon 2.30GHz\n",
            "CPU count           2\n",
            "GPU                 Tesla T4, 15102MiB\n",
            "GPU count           1\n",
            "CUDA                12.1\n",
            "\n",
            "numpy               ✅ 1.26.4>=1.23.0\n",
            "numpy               ✅ 1.26.4<2.0.0; sys_platform == \"darwin\"\n",
            "matplotlib          ✅ 3.10.0>=3.3.0\n",
            "opencv-python       ✅ 4.10.0.84>=4.6.0\n",
            "pillow              ✅ 11.1.0>=7.1.2\n",
            "pyyaml              ✅ 6.0.2>=5.3.1\n",
            "requests            ✅ 2.32.3>=2.23.0\n",
            "scipy               ✅ 1.13.1>=1.4.1\n",
            "torch               ✅ 2.5.1+cu121>=1.8.0\n",
            "torch               ✅ 2.5.1+cu121!=2.4.0,>=1.8.0; sys_platform == \"win32\"\n",
            "torchvision         ✅ 0.20.1+cu121>=0.9.0\n",
            "tqdm                ✅ 4.67.1>=4.64.0\n",
            "psutil              ✅ 5.9.5\n",
            "py-cpuinfo          ✅ 9.0.0\n",
            "pandas              ✅ 2.2.2>=1.1.4\n",
            "seaborn             ✅ 0.13.2>=0.11.0\n",
            "ultralytics-thop    ✅ 2.0.13>=2.0.0\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "from IPython.display import display, Image\n",
        "from IPython import display\n",
        "\n",
        "display.clear_output()\n",
        "!yolo checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-6HvtuMmTfE",
        "outputId": "c82e0950-c45e-443c-a80b-bfb7b89f672a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.58 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11s.pt, data=/content/segmantareDateMedici/data.yaml, epochs=30, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 16.0MB/s]\n",
            "Overriding model.yaml nc=80 with nc=52\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
            "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
            " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
            " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
            " 23        [16, 19, 22]  1    839532  ultralytics.nn.modules.head.Detect           [52, [128, 256, 512]]         \n",
            "YOLO11s summary: 319 layers, 9,447,916 parameters, 9,447,900 gradients, 21.7 GFLOPs\n",
            "\n",
            "Transferred 493/499 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n",
            "100% 5.35M/5.35M [00:00<00:00, 65.3MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/segmantareDateMedici/train/labels... 800 images, 28 backgrounds, 65 corrupt: 100% 800/800 [00:08<00:00, 91.77it/s] \n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/128.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/147.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/15.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/151.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/152.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/160.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/171.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/201.jpg: ignoring corrupt image/label: could not convert string to float: 'T'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/219.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/232.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/242.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/260.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/274.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/280.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/312.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/318.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/325.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/367.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/368.jpg: ignoring corrupt image/label: could not convert string to float: 'K'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/373.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/376.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/430.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/458.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/484.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/493.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/496.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/508.jpg: ignoring corrupt image/label: could not convert string to float: 'T'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/519.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/54.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/541.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/549.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/55.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/56.jpg: ignoring corrupt image/label: could not convert string to float: 'C'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/572.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/580.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/584.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/594.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/605.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/610.jpg: ignoring corrupt image/label: could not convert string to float: 'C'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/633.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/636.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/647.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/665.jpg: ignoring corrupt image/label: could not convert string to float: 'K'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/667.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/682.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/690.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/700.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/701.jpg: ignoring corrupt image/label: could not convert string to float: 'B'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/718.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/719.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/737.jpg: ignoring corrupt image/label: could not convert string to float: 'J'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/741.jpg: ignoring corrupt image/label: could not convert string to float: 'Q'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/754.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/758.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/806.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/838.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/846.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/85.jpg: ignoring corrupt image/label: could not convert string to float: 'C'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/879.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/898.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/946.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/96.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/960.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/961.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/train/images/997.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/segmantareDateMedici/train/labels.cache\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.24 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/segmantareDateMedici/valid/labels... 200 images, 4 backgrounds, 17 corrupt: 100% 200/200 [00:04<00:00, 46.56it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/111.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/187.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/226.jpg: ignoring corrupt image/label: could not convert string to float: 'T'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/271.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/300.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/394.jpg: ignoring corrupt image/label: could not convert string to float: 'J'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/395.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/425.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/509.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/510.jpg: ignoring corrupt image/label: could not convert string to float: 'K'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/699.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/702.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/78.jpg: ignoring corrupt image/label: could not convert string to float: 'K'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/786.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/789.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/824.jpg: ignoring corrupt image/label: could not convert string to float: 'M'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/853.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/segmantareDateMedici/valid/labels.cache\n",
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000179, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/30       5.6G      1.883      4.701      1.393        661        640: 100% 46/46 [00:38<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:07<00:00,  1.24s/it]\n",
            "                   all        183       4635      0.124      0.434     0.0656     0.0427\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/30      5.77G      1.331      2.369      1.054        818        640: 100% 46/46 [00:34<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.32it/s]\n",
            "                   all        183       4635      0.246      0.632      0.317      0.219\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/30      5.48G      1.263      1.798      1.056        571        640: 100% 46/46 [00:34<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:06<00:00,  1.09s/it]\n",
            "                   all        183       4635      0.327      0.728      0.396      0.265\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/30       5.1G      1.217      1.618      1.031        892        640: 100% 46/46 [00:36<00:00,  1.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "                   all        183       4635      0.381      0.776      0.431      0.296\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/30      5.48G      1.185      1.491      1.022        553        640: 100% 46/46 [00:34<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.28it/s]\n",
            "                   all        183       4635      0.424      0.818      0.514      0.357\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/30      5.22G      1.157        1.4       1.01        655        640: 100% 46/46 [00:34<00:00,  1.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "                   all        183       4635      0.446      0.818      0.538      0.375\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/30      5.24G      1.142      1.374      1.003        741        640: 100% 46/46 [00:34<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.79it/s]\n",
            "                   all        183       4635      0.446      0.851      0.497      0.346\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/30         5G      1.126      1.306     0.9952        816        640: 100% 46/46 [00:34<00:00,  1.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:05<00:00,  1.11it/s]\n",
            "                   all        183       4635      0.462      0.892      0.512      0.358\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/30      5.27G      1.117      1.258     0.9921        531        640: 100% 46/46 [00:34<00:00,  1.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.86it/s]\n",
            "                   all        183       4635      0.467      0.889      0.518      0.364\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/30      5.45G      1.125      1.227      0.993        873        640: 100% 46/46 [00:37<00:00,  1.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.73it/s]\n",
            "                   all        183       4635      0.468      0.835      0.538      0.374\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/30      5.75G       1.11        1.2     0.9869        811        640: 100% 46/46 [00:34<00:00,  1.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.49it/s]\n",
            "                   all        183       4635      0.554       0.83      0.679      0.483\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/30      5.47G      1.116        1.1     0.9924        608        640: 100% 46/46 [00:34<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.82it/s]\n",
            "                   all        183       4635      0.787      0.858      0.863      0.613\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/30      5.01G      1.106       1.01     0.9842        586        640: 100% 46/46 [00:34<00:00,  1.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:05<00:00,  1.15it/s]\n",
            "                   all        183       4635      0.852        0.9      0.924      0.654\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/30      6.12G      1.098      0.881     0.9871        720        640: 100% 46/46 [00:34<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.84it/s]\n",
            "                   all        183       4635      0.872      0.899       0.94      0.669\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/30      5.21G      1.092     0.8081     0.9815        653        640: 100% 46/46 [00:36<00:00,  1.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.91it/s]\n",
            "                   all        183       4635      0.912      0.925      0.961      0.684\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/30      4.94G      1.085      0.778     0.9826        865        640: 100% 46/46 [00:34<00:00,  1.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:05<00:00,  1.13it/s]\n",
            "                   all        183       4635      0.916      0.929      0.963      0.687\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/30      5.23G      1.083     0.7505     0.9849        894        640: 100% 46/46 [00:34<00:00,  1.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.93it/s]\n",
            "                   all        183       4635      0.925      0.936      0.969      0.688\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/30      5.69G       1.07     0.7341     0.9784        578        640: 100% 46/46 [00:34<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "                   all        183       4635       0.93      0.912      0.966       0.69\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/30      5.43G      1.071     0.7188     0.9748        572        640: 100% 46/46 [00:33<00:00,  1.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.75it/s]\n",
            "                   all        183       4635       0.94      0.934      0.971      0.693\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/30      5.91G      1.066     0.6982     0.9737        740        640: 100% 46/46 [00:34<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.85it/s]\n",
            "                   all        183       4635      0.932      0.931      0.968      0.695\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/30      4.47G      1.066      0.755      1.005        378        640: 100% 46/46 [00:28<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.19it/s]\n",
            "                   all        183       4635      0.929      0.935      0.969      0.691\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/30      4.46G      1.043     0.6777     0.9912        400        640: 100% 46/46 [00:22<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.47it/s]\n",
            "                   all        183       4635       0.94      0.935      0.969       0.69\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/30      4.48G      1.039     0.6556     0.9878        380        640: 100% 46/46 [00:22<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.15it/s]\n",
            "                   all        183       4635      0.943       0.94      0.973      0.696\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/30      4.46G       1.04     0.6816     0.9894        377        640: 100% 46/46 [00:22<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.28it/s]\n",
            "                   all        183       4635      0.947      0.936      0.973      0.696\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/30      4.48G      1.033     0.6478     0.9913        340        640: 100% 46/46 [00:21<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.29it/s]\n",
            "                   all        183       4635      0.934      0.934       0.97      0.696\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/30      4.46G      1.027     0.6196     0.9868        393        640: 100% 46/46 [00:24<00:00,  1.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.13it/s]\n",
            "                   all        183       4635      0.947      0.936      0.973      0.698\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/30      4.48G      1.031     0.6176     0.9782        378        640: 100% 46/46 [00:21<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.02it/s]\n",
            "                   all        183       4635      0.944       0.94      0.973      0.698\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/30      4.46G      1.026      0.619     0.9821        366        640: 100% 46/46 [00:23<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:04<00:00,  1.33it/s]\n",
            "                   all        183       4635      0.949       0.94      0.975      0.698\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/30      4.47G      1.022     0.6034     0.9834        384        640: 100% 46/46 [00:24<00:00,  1.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.80it/s]\n",
            "                   all        183       4635      0.949      0.939      0.975      0.701\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/30      4.45G      1.023     0.6024     0.9839        393        640: 100% 46/46 [00:22<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:02<00:00,  2.31it/s]\n",
            "                   all        183       4635      0.948      0.943      0.975      0.701\n",
            "\n",
            "30 epochs completed in 0.309 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 19.2MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 19.2MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics 8.3.58 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11s summary (fused): 238 layers, 9,432,924 parameters, 0 gradients, 21.4 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:05<00:00,  1.05it/s]\n",
            "                   all        183       4635      0.949      0.938      0.975      0.701\n",
            "                     2         70         70      0.942      0.926      0.966      0.655\n",
            "                     3        139        139      0.955       0.91      0.957       0.73\n",
            "                     4        141        141      0.934      0.957      0.958      0.707\n",
            "                     5        143        143      0.929      0.895      0.951      0.678\n",
            "                     6        144        144      0.926      0.944      0.963      0.655\n",
            "                     7        165        165      0.972      0.964       0.99      0.698\n",
            "                     8        162        162      0.987      0.938      0.987      0.669\n",
            "                     9        161        161      0.963      0.969      0.988      0.698\n",
            "                    10        162        162       0.99      0.944      0.993      0.694\n",
            "                    11        162        162      0.961       0.92      0.981      0.656\n",
            "                    12        164        164      0.945      0.935      0.973      0.689\n",
            "                    13        156        156      0.921      0.901      0.947      0.621\n",
            "                    14        142        142      0.961      0.901       0.98      0.685\n",
            "                    15        145        145       0.95      0.924      0.966      0.717\n",
            "                    16        138        138      0.911      0.894      0.963      0.733\n",
            "                    17         69         69      0.896      0.928      0.975      0.716\n",
            "                    18         74         74      0.973      0.977      0.992      0.769\n",
            "                    19        142        142      0.959      0.951      0.988      0.815\n",
            "                    20        135        135       0.94      0.978      0.988      0.834\n",
            "                    21        161        161      0.974      0.939       0.98      0.731\n",
            "                    22        160        160      0.963      0.971      0.989       0.72\n",
            "                    23        175        175      0.966       0.96      0.991      0.704\n",
            "                    24        170        170      0.948      0.929      0.978      0.647\n",
            "                    25        172        172      0.922      0.894      0.948      0.588\n",
            "                    26        170        170      0.885      0.882      0.946      0.591\n",
            "                    27        166        166      0.963      0.945       0.97      0.621\n",
            "                    28        174        174      0.959       0.96      0.981      0.685\n",
            "                    29        167        167      0.945      0.931      0.975      0.706\n",
            "                    30        148        148      0.946      0.947      0.975      0.678\n",
            "                    31        145        145      0.934      0.978      0.983      0.796\n",
            "                    32        138        138      0.946      0.964       0.99      0.803\n",
            "                     A         75         75          1       0.96      0.994      0.762\n",
            "Speed: 0.1ms preprocess, 3.2ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect mode=train model=\"yolo11s.pt\" data=/content/segmantareDateMedici/data.yaml epochs=30 imgsz=640"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WfDvZPTn1M8",
        "outputId": "4de090ea-faeb-4a15-9de8-342fae75c15a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.58 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11s summary (fused): 238 layers, 9,432,924 parameters, 0 gradients, 21.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/segmantareDateMedici/valid/labels.cache... 200 images, 4 backgrounds, 17 corrupt: 100% 200/200 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/111.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/187.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/226.jpg: ignoring corrupt image/label: could not convert string to float: 'T'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/271.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/300.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/394.jpg: ignoring corrupt image/label: could not convert string to float: 'J'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/395.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/425.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/509.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/510.jpg: ignoring corrupt image/label: could not convert string to float: 'K'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/699.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/702.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/78.jpg: ignoring corrupt image/label: could not convert string to float: 'K'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/786.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/789.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/824.jpg: ignoring corrupt image/label: could not convert string to float: 'M'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/segmantareDateMedici/valid/images/853.jpg: ignoring corrupt image/label: could not convert string to float: 'A'\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:05<00:00,  2.38it/s]\n",
            "                   all        183       4635      0.949      0.939      0.975      0.701\n",
            "                     2         70         70      0.942      0.926      0.967      0.658\n",
            "                     3        139        139      0.955      0.911      0.957       0.73\n",
            "                     4        141        141      0.934      0.957      0.959      0.706\n",
            "                     5        143        143      0.929      0.895      0.951      0.674\n",
            "                     6        144        144      0.932      0.951      0.963      0.654\n",
            "                     7        165        165      0.976      0.967       0.99      0.694\n",
            "                     8        162        162      0.987      0.939      0.987      0.666\n",
            "                     9        161        161      0.963      0.969      0.988      0.696\n",
            "                    10        162        162       0.99      0.944      0.993      0.691\n",
            "                    11        162        162      0.961      0.921      0.982      0.656\n",
            "                    12        164        164      0.945      0.936      0.973      0.689\n",
            "                    13        156        156      0.921      0.903      0.948      0.622\n",
            "                    14        142        142      0.961      0.901       0.98      0.689\n",
            "                    15        145        145       0.95      0.924      0.966      0.719\n",
            "                    16        138        138      0.911      0.894      0.961      0.734\n",
            "                    17         69         69      0.884      0.928      0.974      0.717\n",
            "                    18         74         74      0.973      0.977      0.992      0.766\n",
            "                    19        142        142      0.959      0.951      0.988      0.815\n",
            "                    20        135        135       0.94      0.978      0.988      0.833\n",
            "                    21        161        161      0.974       0.94       0.98       0.73\n",
            "                    22        160        160      0.963      0.972      0.989      0.716\n",
            "                    23        175        175      0.966       0.96      0.991      0.701\n",
            "                    24        170        170      0.947      0.929      0.978      0.647\n",
            "                    25        172        172      0.917      0.896      0.947       0.59\n",
            "                    26        170        170      0.887      0.882      0.946      0.588\n",
            "                    27        166        166      0.963      0.945       0.97      0.618\n",
            "                    28        174        174      0.965       0.96      0.981      0.688\n",
            "                    29        167        167      0.945      0.932      0.975      0.712\n",
            "                    30        148        148      0.946      0.947      0.975       0.68\n",
            "                    31        145        145      0.934      0.977      0.983      0.798\n",
            "                    32        138        138      0.946      0.964       0.99      0.802\n",
            "                     A         75         75          1       0.96      0.994      0.762\n",
            "Speed: 0.1ms preprocess, 7.5ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect mode=val model=/content/runs/detect/train2/weights/best.pt data=/content/segmantareDateMedici/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-BYKaARsRcn",
        "outputId": "d8e7bd74-f3d7-4576-c6aa-3836fc4651bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: runs/ (stored 0%)\n",
            "  adding: runs/detect/ (stored 0%)\n",
            "  adding: runs/detect/train2/ (stored 0%)\n",
            "  adding: runs/detect/train2/train_batch921.jpg (deflated 19%)\n",
            "  adding: runs/detect/train2/val_batch1_pred.jpg (deflated 8%)\n",
            "  adding: runs/detect/train2/val_batch2_labels.jpg (deflated 8%)\n",
            "  adding: runs/detect/train2/train_batch1.jpg (deflated 4%)\n",
            "  adding: runs/detect/train2/train_batch0.jpg (deflated 5%)\n",
            "  adding: runs/detect/train2/F1_curve.png (deflated 10%)\n",
            "  adding: runs/detect/train2/labels_correlogram.jpg (deflated 33%)\n",
            "  adding: runs/detect/train2/events.out.tfevents.1736361420.38147b932a14.1615.0 (deflated 92%)\n",
            "  adding: runs/detect/train2/args.yaml (deflated 53%)\n",
            "  adding: runs/detect/train2/val_batch2_pred.jpg (deflated 7%)\n",
            "  adding: runs/detect/train2/PR_curve.png (deflated 17%)\n",
            "  adding: runs/detect/train2/val_batch0_labels.jpg (deflated 8%)\n",
            "  adding: runs/detect/train2/R_curve.png (deflated 11%)\n",
            "  adding: runs/detect/train2/val_batch0_pred.jpg (deflated 8%)\n",
            "  adding: runs/detect/train2/results.csv (deflated 61%)\n",
            "  adding: runs/detect/train2/train_batch2.jpg (deflated 6%)\n",
            "  adding: runs/detect/train2/confusion_matrix_normalized.png (deflated 27%)\n",
            "  adding: runs/detect/train2/val_batch1_labels.jpg (deflated 8%)\n",
            "  adding: runs/detect/train2/weights/ (stored 0%)\n",
            "  adding: runs/detect/train2/weights/last.pt (deflated 8%)\n",
            "  adding: runs/detect/train2/weights/best.pt (deflated 8%)\n",
            "  adding: runs/detect/train2/train_batch922.jpg (deflated 13%)\n",
            "  adding: runs/detect/train2/P_curve.png (deflated 11%)\n",
            "  adding: runs/detect/train2/train_batch920.jpg (deflated 13%)\n",
            "  adding: runs/detect/train2/confusion_matrix.png (deflated 26%)\n",
            "  adding: runs/detect/train2/results.png (deflated 8%)\n",
            "  adding: runs/detect/train2/labels.jpg (deflated 39%)\n",
            "  adding: runs/detect/val/ (stored 0%)\n",
            "  adding: runs/detect/val/val_batch1_pred.jpg (deflated 8%)\n",
            "  adding: runs/detect/val/val_batch2_labels.jpg (deflated 8%)\n",
            "  adding: runs/detect/val/F1_curve.png (deflated 10%)\n",
            "  adding: runs/detect/val/val_batch2_pred.jpg (deflated 8%)\n",
            "  adding: runs/detect/val/PR_curve.png (deflated 17%)\n",
            "  adding: runs/detect/val/val_batch0_labels.jpg (deflated 8%)\n",
            "  adding: runs/detect/val/R_curve.png (deflated 11%)\n",
            "  adding: runs/detect/val/val_batch0_pred.jpg (deflated 8%)\n",
            "  adding: runs/detect/val/confusion_matrix_normalized.png (deflated 27%)\n",
            "  adding: runs/detect/val/val_batch1_labels.jpg (deflated 8%)\n",
            "  adding: runs/detect/val/P_curve.png (deflated 11%)\n",
            "  adding: runs/detect/val/confusion_matrix.png (deflated 26%)\n",
            "  adding: runs/detect/train/ (stored 0%)\n",
            "  adding: runs/detect/train/args.yaml (deflated 53%)\n",
            "  adding: runs/detect/train/weights/ (stored 0%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r runs.zip ./runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "b9NaopOhTuR7",
        "outputId": "93f42dfa-ec43-45ba-bafa-c900e520ef6a"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_5f8bb5b7-f043-4f04-89e0-f51f4cd63ed2\", \"runs.zip\", 45295607)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/runs.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fjm1yjfpsRtC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
