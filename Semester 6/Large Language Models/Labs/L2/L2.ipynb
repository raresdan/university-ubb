{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ab171c-90f3-4481-afb8-d7420ae8f042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "     ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/10.0 MB 1.7 MB/s eta 0:00:06\n",
      "      --------------------------------------- 0.2/10.0 MB 1.8 MB/s eta 0:00:06\n",
      "      --------------------------------------- 0.2/10.0 MB 1.7 MB/s eta 0:00:06\n",
      "     - -------------------------------------- 0.3/10.0 MB 2.1 MB/s eta 0:00:05\n",
      "     - -------------------------------------- 0.4/10.0 MB 2.1 MB/s eta 0:00:05\n",
      "     -- ------------------------------------- 0.6/10.0 MB 2.0 MB/s eta 0:00:05\n",
      "     -- ------------------------------------- 0.7/10.0 MB 2.4 MB/s eta 0:00:04\n",
      "     --- ------------------------------------ 0.9/10.0 MB 2.5 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 1.1/10.0 MB 2.7 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 1.2/10.0 MB 2.7 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 1.5/10.0 MB 2.9 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 1.6/10.0 MB 3.0 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 1.8/10.0 MB 3.1 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 1.8/10.0 MB 2.9 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.0/10.0 MB 2.9 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 2.2/10.0 MB 3.0 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 2.4/10.0 MB 3.1 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 2.5/10.0 MB 3.1 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 2.7/10.0 MB 3.1 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 2.9/10.0 MB 3.2 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 3.0/10.0 MB 3.2 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 3.3/10.0 MB 3.3 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 3.4/10.0 MB 3.3 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 3.7/10.0 MB 3.4 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 3.9/10.0 MB 3.5 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 4.2/10.0 MB 3.6 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 4.6/10.0 MB 3.7 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 4.8/10.0 MB 3.7 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 5.2/10.0 MB 4.0 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 5.5/10.0 MB 4.0 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 5.8/10.0 MB 4.1 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 6.2/10.0 MB 4.2 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 6.4/10.0 MB 4.3 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 6.8/10.0 MB 4.4 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 7.0/10.0 MB 4.5 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 7.0/10.0 MB 4.5 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 7.3/10.0 MB 4.4 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 7.7/10.0 MB 4.5 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 7.9/10.0 MB 4.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 8.6/10.0 MB 4.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 9.2/10.0 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  9.9/10.0 MB 5.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  10.0/10.0 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 10.0/10.0 MB 5.1 MB/s eta 0:00:00\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.20-py3-none-any.whl (1.0 MB)\n",
      "     ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "     --------------------------- ------------ 0.7/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.0/1.0 MB 890.1 kB/s eta 0:00:00\n",
      "Collecting torch\n",
      "  Downloading torch-2.6.0-cp310-cp310-win_amd64.whl (204.2 MB)\n",
      "     ---------------------------------------- 0.0/204.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.3/204.2 MB 8.9 MB/s eta 0:00:23\n",
      "     --------------------------------------- 1.0/204.2 MB 12.9 MB/s eta 0:00:16\n",
      "     --------------------------------------- 1.9/204.2 MB 13.7 MB/s eta 0:00:15\n",
      "      -------------------------------------- 2.8/204.2 MB 16.1 MB/s eta 0:00:13\n",
      "      -------------------------------------- 3.7/204.2 MB 16.7 MB/s eta 0:00:12\n",
      "      -------------------------------------- 4.5/204.2 MB 16.7 MB/s eta 0:00:12\n",
      "      -------------------------------------- 4.9/204.2 MB 15.5 MB/s eta 0:00:13\n",
      "     - ------------------------------------- 5.4/204.2 MB 15.1 MB/s eta 0:00:14\n",
      "     - ------------------------------------- 6.5/204.2 MB 15.9 MB/s eta 0:00:13\n",
      "     - ------------------------------------- 7.7/204.2 MB 16.4 MB/s eta 0:00:12\n",
      "     - ------------------------------------- 8.3/204.2 MB 16.0 MB/s eta 0:00:13\n",
      "     - ------------------------------------- 8.8/204.2 MB 16.6 MB/s eta 0:00:12\n",
      "     - ------------------------------------- 9.9/204.2 MB 16.6 MB/s eta 0:00:12\n",
      "     - ------------------------------------ 10.2/204.2 MB 15.6 MB/s eta 0:00:13\n",
      "     - ------------------------------------ 10.6/204.2 MB 16.4 MB/s eta 0:00:12\n",
      "     -- ----------------------------------- 11.8/204.2 MB 16.4 MB/s eta 0:00:12\n",
      "     -- ----------------------------------- 12.6/204.2 MB 16.4 MB/s eta 0:00:12\n",
      "     -- ----------------------------------- 13.6/204.2 MB 16.4 MB/s eta 0:00:12\n",
      "     -- ----------------------------------- 14.5/204.2 MB 16.8 MB/s eta 0:00:12\n",
      "     -- ----------------------------------- 15.4/204.2 MB 18.2 MB/s eta 0:00:11\n",
      "     --- ---------------------------------- 16.3/204.2 MB 17.7 MB/s eta 0:00:11\n",
      "     --- ---------------------------------- 17.9/204.2 MB 18.7 MB/s eta 0:00:10\n",
      "     --- ---------------------------------- 18.7/204.2 MB 18.2 MB/s eta 0:00:11\n",
      "     --- ---------------------------------- 20.0/204.2 MB 19.3 MB/s eta 0:00:10\n",
      "     ---- --------------------------------- 21.5/204.2 MB 22.6 MB/s eta 0:00:09\n",
      "     ---- --------------------------------- 22.6/204.2 MB 22.6 MB/s eta 0:00:09\n",
      "     ---- --------------------------------- 23.8/204.2 MB 22.6 MB/s eta 0:00:08\n",
      "     ---- --------------------------------- 24.5/204.2 MB 22.5 MB/s eta 0:00:08\n",
      "     ---- --------------------------------- 25.7/204.2 MB 24.2 MB/s eta 0:00:08\n",
      "     ----- -------------------------------- 27.2/204.2 MB 24.2 MB/s eta 0:00:08\n",
      "     ----- -------------------------------- 28.1/204.2 MB 23.4 MB/s eta 0:00:08\n",
      "     ----- -------------------------------- 29.6/204.2 MB 26.2 MB/s eta 0:00:07\n",
      "     ----- -------------------------------- 30.6/204.2 MB 25.2 MB/s eta 0:00:07\n",
      "     ----- -------------------------------- 32.0/204.2 MB 25.2 MB/s eta 0:00:07\n",
      "     ------ ------------------------------- 33.1/204.2 MB 25.1 MB/s eta 0:00:07\n",
      "     ------ ------------------------------- 34.5/204.2 MB 27.3 MB/s eta 0:00:07\n",
      "     ------ ------------------------------- 35.5/204.2 MB 26.2 MB/s eta 0:00:07\n",
      "     ------ ------------------------------- 36.5/204.2 MB 26.2 MB/s eta 0:00:07\n",
      "     ------- ------------------------------ 37.8/204.2 MB 26.2 MB/s eta 0:00:07\n",
      "     ------- ------------------------------ 38.8/204.2 MB 26.2 MB/s eta 0:00:07\n",
      "     ------- ------------------------------ 39.7/204.2 MB 24.2 MB/s eta 0:00:07\n",
      "     ------- ------------------------------ 41.0/204.2 MB 25.2 MB/s eta 0:00:07\n",
      "     ------- ------------------------------ 41.8/204.2 MB 24.2 MB/s eta 0:00:07\n",
      "     ------- ------------------------------ 42.8/204.2 MB 24.2 MB/s eta 0:00:07\n",
      "     -------- ----------------------------- 43.7/204.2 MB 22.6 MB/s eta 0:00:08\n",
      "     -------- ----------------------------- 44.9/204.2 MB 22.6 MB/s eta 0:00:08\n",
      "     -------- ----------------------------- 46.4/204.2 MB 23.4 MB/s eta 0:00:07\n",
      "     -------- ----------------------------- 47.7/204.2 MB 24.3 MB/s eta 0:00:07\n",
      "     --------- ---------------------------- 48.8/204.2 MB 24.2 MB/s eta 0:00:07\n",
      "     --------- ---------------------------- 50.1/204.2 MB 26.2 MB/s eta 0:00:06\n",
      "     --------- ---------------------------- 51.3/204.2 MB 25.2 MB/s eta 0:00:07\n",
      "     --------- ---------------------------- 52.4/204.2 MB 24.2 MB/s eta 0:00:07\n",
      "     --------- ---------------------------- 53.6/204.2 MB 26.2 MB/s eta 0:00:06\n",
      "     ---------- --------------------------- 54.5/204.2 MB 26.2 MB/s eta 0:00:06\n",
      "     ---------- --------------------------- 55.4/204.2 MB 25.1 MB/s eta 0:00:06\n",
      "     ---------- --------------------------- 56.7/204.2 MB 24.2 MB/s eta 0:00:07\n",
      "     ---------- --------------------------- 58.5/204.2 MB 24.2 MB/s eta 0:00:07\n",
      "     ----------- -------------------------- 59.4/204.2 MB 24.2 MB/s eta 0:00:06\n",
      "     ----------- -------------------------- 60.4/204.2 MB 24.2 MB/s eta 0:00:06\n",
      "     ----------- -------------------------- 61.4/204.2 MB 22.5 MB/s eta 0:00:07\n",
      "     ----------- -------------------------- 63.0/204.2 MB 24.3 MB/s eta 0:00:06\n",
      "     ----------- -------------------------- 64.0/204.2 MB 24.2 MB/s eta 0:00:06\n",
      "     ------------ ------------------------- 65.0/204.2 MB 24.2 MB/s eta 0:00:06\n",
      "     ------------ ------------------------- 66.2/204.2 MB 26.2 MB/s eta 0:00:06\n",
      "     ------------ ------------------------- 67.3/204.2 MB 26.2 MB/s eta 0:00:06\n",
      "     ------------ ------------------------- 68.5/204.2 MB 25.2 MB/s eta 0:00:06\n",
      "     ------------ ------------------------- 69.8/204.2 MB 25.1 MB/s eta 0:00:06\n",
      "     ------------- ------------------------ 70.7/204.2 MB 24.2 MB/s eta 0:00:06\n",
      "     ------------- ------------------------ 71.9/204.2 MB 24.3 MB/s eta 0:00:06\n",
      "     ------------- ------------------------ 72.2/204.2 MB 24.2 MB/s eta 0:00:06\n",
      "     ------------- ------------------------ 72.7/204.2 MB 21.8 MB/s eta 0:00:07\n",
      "     ------------- ------------------------ 73.4/204.2 MB 21.1 MB/s eta 0:00:07\n",
      "     ------------- ------------------------ 74.2/204.2 MB 20.5 MB/s eta 0:00:07\n",
      "     ------------- ------------------------ 75.2/204.2 MB 19.9 MB/s eta 0:00:07\n",
      "     -------------- ----------------------- 75.4/204.2 MB 18.7 MB/s eta 0:00:07\n",
      "     -------------- ----------------------- 76.3/204.2 MB 18.2 MB/s eta 0:00:08\n",
      "     -------------- ----------------------- 77.1/204.2 MB 17.7 MB/s eta 0:00:08\n",
      "     -------------- ----------------------- 77.3/204.2 MB 16.4 MB/s eta 0:00:08\n",
      "     -------------- ----------------------- 77.9/204.2 MB 15.6 MB/s eta 0:00:09\n",
      "     -------------- ----------------------- 79.0/204.2 MB 16.4 MB/s eta 0:00:08\n",
      "     -------------- ----------------------- 79.7/204.2 MB 16.0 MB/s eta 0:00:08\n",
      "     -------------- ----------------------- 80.5/204.2 MB 15.2 MB/s eta 0:00:09\n",
      "     --------------- ---------------------- 81.3/204.2 MB 15.2 MB/s eta 0:00:09\n",
      "     --------------- ---------------------- 81.9/204.2 MB 14.6 MB/s eta 0:00:09\n",
      "     --------------- ---------------------- 83.4/204.2 MB 16.8 MB/s eta 0:00:08\n",
      "     --------------- ---------------------- 84.1/204.2 MB 16.8 MB/s eta 0:00:08\n",
      "     --------------- ---------------------- 85.4/204.2 MB 17.2 MB/s eta 0:00:07\n",
      "     ---------------- --------------------- 86.8/204.2 MB 18.7 MB/s eta 0:00:07\n",
      "     ---------------- --------------------- 88.0/204.2 MB 21.1 MB/s eta 0:00:06\n",
      "     ---------------- --------------------- 89.0/204.2 MB 22.5 MB/s eta 0:00:06\n",
      "     ---------------- --------------------- 90.8/204.2 MB 25.2 MB/s eta 0:00:05\n",
      "     ----------------- -------------------- 91.9/204.2 MB 27.3 MB/s eta 0:00:05\n",
      "     ----------------- -------------------- 93.2/204.2 MB 26.2 MB/s eta 0:00:05\n",
      "     ----------------- -------------------- 94.4/204.2 MB 27.3 MB/s eta 0:00:05\n",
      "     ----------------- -------------------- 95.3/204.2 MB 26.2 MB/s eta 0:00:05\n",
      "     ----------------- -------------------- 96.0/204.2 MB 25.2 MB/s eta 0:00:05\n",
      "     ------------------ ------------------- 97.2/204.2 MB 25.2 MB/s eta 0:00:05\n",
      "     ------------------ ------------------- 98.1/204.2 MB 24.2 MB/s eta 0:00:05\n",
      "     ------------------ ------------------- 98.6/204.2 MB 24.2 MB/s eta 0:00:05\n",
      "     ------------------ ------------------- 99.6/204.2 MB 23.4 MB/s eta 0:00:05\n",
      "     ------------------ ------------------ 100.3/204.2 MB 21.1 MB/s eta 0:00:05\n",
      "     ------------------ ------------------ 101.4/204.2 MB 21.1 MB/s eta 0:00:05\n",
      "     ------------------ ------------------ 102.8/204.2 MB 21.8 MB/s eta 0:00:05\n",
      "     ------------------ ------------------ 104.6/204.2 MB 21.9 MB/s eta 0:00:05\n",
      "     ------------------- ----------------- 106.0/204.2 MB 24.2 MB/s eta 0:00:05\n",
      "     ------------------- ----------------- 107.1/204.2 MB 24.2 MB/s eta 0:00:05\n",
      "     ------------------- ----------------- 108.2/204.2 MB 24.2 MB/s eta 0:00:04\n",
      "     ------------------- ----------------- 109.0/204.2 MB 25.2 MB/s eta 0:00:04\n",
      "     -------------------- ---------------- 110.4/204.2 MB 27.3 MB/s eta 0:00:04\n",
      "     -------------------- ---------------- 111.6/204.2 MB 26.2 MB/s eta 0:00:04\n",
      "     -------------------- ---------------- 113.0/204.2 MB 27.3 MB/s eta 0:00:04\n",
      "     -------------------- ---------------- 114.0/204.2 MB 26.2 MB/s eta 0:00:04\n",
      "     -------------------- ---------------- 115.1/204.2 MB 25.2 MB/s eta 0:00:04\n",
      "     --------------------- --------------- 116.1/204.2 MB 24.2 MB/s eta 0:00:04\n",
      "     --------------------- --------------- 117.1/204.2 MB 24.3 MB/s eta 0:00:04\n",
      "     --------------------- --------------- 117.6/204.2 MB 24.2 MB/s eta 0:00:04\n",
      "     --------------------- --------------- 117.8/204.2 MB 21.8 MB/s eta 0:00:04\n",
      "     --------------------- --------------- 118.9/204.2 MB 21.1 MB/s eta 0:00:05\n",
      "     --------------------- --------------- 119.6/204.2 MB 21.9 MB/s eta 0:00:04\n",
      "     --------------------- --------------- 120.5/204.2 MB 19.8 MB/s eta 0:00:05\n",
      "     ---------------------- -------------- 121.6/204.2 MB 20.5 MB/s eta 0:00:05\n",
      "     ---------------------- -------------- 122.9/204.2 MB 19.8 MB/s eta 0:00:05\n",
      "     ---------------------- -------------- 124.3/204.2 MB 20.5 MB/s eta 0:00:04\n",
      "     ---------------------- -------------- 125.4/204.2 MB 21.1 MB/s eta 0:00:04\n",
      "     ---------------------- -------------- 126.7/204.2 MB 21.8 MB/s eta 0:00:04\n",
      "     ----------------------- ------------- 127.6/204.2 MB 21.1 MB/s eta 0:00:04\n",
      "     ----------------------- ------------- 129.1/204.2 MB 25.2 MB/s eta 0:00:03\n",
      "     ----------------------- ------------- 130.5/204.2 MB 27.3 MB/s eta 0:00:03\n",
      "     ----------------------- ------------- 131.8/204.2 MB 27.3 MB/s eta 0:00:03\n",
      "     ------------------------ ------------ 132.8/204.2 MB 28.5 MB/s eta 0:00:03\n",
      "     ------------------------ ------------ 134.0/204.2 MB 26.2 MB/s eta 0:00:03\n",
      "     ------------------------ ------------ 135.5/204.2 MB 27.3 MB/s eta 0:00:03\n",
      "     ------------------------ ------------ 136.0/204.2 MB 25.1 MB/s eta 0:00:03\n",
      "     ------------------------ ------------ 137.4/204.2 MB 26.2 MB/s eta 0:00:03\n",
      "     ------------------------- ----------- 138.1/204.2 MB 26.2 MB/s eta 0:00:03\n",
      "     ------------------------- ----------- 139.1/204.2 MB 25.1 MB/s eta 0:00:03\n",
      "     ------------------------- ----------- 139.2/204.2 MB 24.2 MB/s eta 0:00:03\n",
      "     ------------------------- ----------- 139.9/204.2 MB 21.8 MB/s eta 0:00:03\n",
      "     ------------------------- ----------- 140.2/204.2 MB 20.5 MB/s eta 0:00:04\n",
      "     ------------------------- ----------- 140.3/204.2 MB 19.3 MB/s eta 0:00:04\n",
      "     ------------------------- ----------- 140.9/204.2 MB 18.2 MB/s eta 0:00:04\n",
      "     ------------------------- ----------- 141.1/204.2 MB 17.2 MB/s eta 0:00:04\n",
      "     ------------------------- ----------- 141.4/204.2 MB 15.6 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 141.6/204.2 MB 14.9 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 142.0/204.2 MB 14.2 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 142.5/204.2 MB 13.6 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 142.8/204.2 MB 13.1 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 143.5/204.2 MB 13.1 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 144.7/204.2 MB 12.8 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 145.8/204.2 MB 13.1 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 146.9/204.2 MB 13.1 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 148.3/204.2 MB 13.6 MB/s eta 0:00:05\n",
      "     --------------------------- --------- 149.4/204.2 MB 13.6 MB/s eta 0:00:05\n",
      "     --------------------------- --------- 150.7/204.2 MB 16.8 MB/s eta 0:00:04\n",
      "     --------------------------- --------- 152.2/204.2 MB 22.6 MB/s eta 0:00:03\n",
      "     --------------------------- --------- 153.5/204.2 MB 26.2 MB/s eta 0:00:02\n",
      "     ---------------------------- -------- 154.7/204.2 MB 28.4 MB/s eta 0:00:02\n",
      "     ---------------------------- -------- 155.9/204.2 MB 28.5 MB/s eta 0:00:02\n",
      "     ---------------------------- -------- 157.3/204.2 MB 29.7 MB/s eta 0:00:02\n",
      "     ---------------------------- -------- 157.7/204.2 MB 27.3 MB/s eta 0:00:02\n",
      "     ---------------------------- -------- 158.4/204.2 MB 25.1 MB/s eta 0:00:02\n",
      "     ---------------------------- -------- 159.2/204.2 MB 26.2 MB/s eta 0:00:02\n",
      "     ----------------------------- ------- 160.6/204.2 MB 24.2 MB/s eta 0:00:02\n",
      "     ----------------------------- ------- 161.9/204.2 MB 24.2 MB/s eta 0:00:02\n",
      "     ----------------------------- ------- 163.1/204.2 MB 24.2 MB/s eta 0:00:02\n",
      "     ----------------------------- ------- 164.7/204.2 MB 24.2 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 165.9/204.2 MB 24.2 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 167.2/204.2 MB 24.2 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 168.9/204.2 MB 28.4 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 170.3/204.2 MB 28.5 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 171.8/204.2 MB 29.7 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 173.0/204.2 MB 28.4 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 173.8/204.2 MB 27.3 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 174.8/204.2 MB 26.2 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 175.6/204.2 MB 27.3 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 177.1/204.2 MB 25.2 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 178.4/204.2 MB 25.2 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 179.7/204.2 MB 25.2 MB/s eta 0:00:01\n",
      "     -------------------------------- ---- 180.9/204.2 MB 24.2 MB/s eta 0:00:01\n",
      "     --------------------------------- --- 182.4/204.2 MB 24.2 MB/s eta 0:00:01\n",
      "     --------------------------------- --- 184.0/204.2 MB 27.3 MB/s eta 0:00:01\n",
      "     --------------------------------- --- 185.1/204.2 MB 27.3 MB/s eta 0:00:01\n",
      "     --------------------------------- --- 186.1/204.2 MB 28.5 MB/s eta 0:00:01\n",
      "     --------------------------------- --- 187.3/204.2 MB 28.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 189.0/204.2 MB 28.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 189.8/204.2 MB 27.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 191.1/204.2 MB 27.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 192.3/204.2 MB 27.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 193.4/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 194.6/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 196.5/204.2 MB 28.4 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 197.4/204.2 MB 27.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 198.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  199.8/204.2 MB 27.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  200.7/204.2 MB 27.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  202.2/204.2 MB 27.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  202.9/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  203.7/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/204.2 MB 26.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- 204.2/204.2 MB 3.0 MB/s eta 0:00:00\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
      "     ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "     ---------------- ----------------------- 1.0/2.5 MB 32.4 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 2.1/2.5 MB 27.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 MB 26.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.5/2.5 MB 17.8 MB/s eta 0:00:00\n",
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Collecting tqdm>=4.27\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "Collecting tokenizers<0.22,>=0.21\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.1/2.4 MB 2.6 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 1.0/2.4 MB 11.0 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 1.9/2.4 MB 13.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 MB 12.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.4/2.4 MB 11.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\_documente_rares\\desktop\\semester 6\\large language models\\l2\\venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0\n",
      "  Downloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "     ---------------------------------------- 0.0/469.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/469.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/469.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/469.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/469.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/469.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/469.0 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 30.7/469.0 kB ? eta -:--:--\n",
      "     -------------- ----------------------- 184.3/469.0 kB 5.6 MB/s eta 0:00:01\n",
      "     ---------------------------------- --- 430.1/469.0 kB 4.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- --- 430.1/469.0 kB 4.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- 469.0/469.0 kB 2.7 MB/s eta 0:00:00\n",
      "Collecting numpy>=1.17\n",
      "  Downloading numpy-2.2.4-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "     ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.9 MB 8.6 MB/s eta 0:00:02\n",
      "      --------------------------------------- 0.3/12.9 MB 8.6 MB/s eta 0:00:02\n",
      "      --------------------------------------- 0.3/12.9 MB 8.6 MB/s eta 0:00:02\n",
      "      --------------------------------------- 0.3/12.9 MB 8.6 MB/s eta 0:00:02\n",
      "      --------------------------------------- 0.3/12.9 MB 8.6 MB/s eta 0:00:02\n",
      "      --------------------------------------- 0.3/12.9 MB 8.6 MB/s eta 0:00:02\n",
      "      --------------------------------------- 0.3/12.9 MB 8.6 MB/s eta 0:00:02\n",
      "     - -------------------------------------- 0.5/12.9 MB 1.5 MB/s eta 0:00:09\n",
      "     - -------------------------------------- 0.5/12.9 MB 1.5 MB/s eta 0:00:09\n",
      "     - -------------------------------------- 0.5/12.9 MB 1.5 MB/s eta 0:00:09\n",
      "     - -------------------------------------- 0.5/12.9 MB 1.5 MB/s eta 0:00:09\n",
      "     - -------------------------------------- 0.6/12.9 MB 1.2 MB/s eta 0:00:11\n",
      "     --- ------------------------------------ 1.2/12.9 MB 2.0 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 1.5/12.9 MB 2.4 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 1.7/12.9 MB 2.6 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 1.9/12.9 MB 2.7 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 1.9/12.9 MB 2.7 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 1.9/12.9 MB 2.7 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 1.9/12.9 MB 2.7 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 1.9/12.9 MB 2.7 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 2.3/12.9 MB 2.5 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 2.3/12.9 MB 2.5 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 2.3/12.9 MB 2.5 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 2.3/12.9 MB 2.5 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 2.3/12.9 MB 2.1 MB/s eta 0:00:06\n",
      "     ------- -------------------------------- 2.5/12.9 MB 2.1 MB/s eta 0:00:05\n",
      "     -------- ------------------------------- 2.8/12.9 MB 2.3 MB/s eta 0:00:05\n",
      "     --------- ------------------------------ 3.0/12.9 MB 2.4 MB/s eta 0:00:05\n",
      "     --------- ------------------------------ 3.0/12.9 MB 2.4 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.4/12.9 MB 2.6 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 3.4/12.9 MB 2.6 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 3.4/12.9 MB 2.6 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 3.8/12.9 MB 2.6 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 3.9/12.9 MB 2.6 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 4.0/12.9 MB 2.6 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 4.1/12.9 MB 2.6 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 4.6/12.9 MB 2.8 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 4.6/12.9 MB 2.8 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 4.6/12.9 MB 2.8 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 4.9/12.9 MB 2.7 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 5.1/12.9 MB 2.8 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.5/12.9 MB 2.9 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.5/12.9 MB 2.9 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 5.6/12.9 MB 2.9 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 5.6/12.9 MB 2.9 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 5.6/12.9 MB 2.9 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 5.6/12.9 MB 2.9 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 5.9/12.9 MB 2.8 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 5.9/12.9 MB 2.8 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 5.9/12.9 MB 2.8 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 5.9/12.9 MB 2.8 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 5.9/12.9 MB 2.8 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 6.0/12.9 MB 2.5 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 6.3/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 6.6/12.9 MB 2.7 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 6.7/12.9 MB 2.7 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 6.8/12.9 MB 2.7 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 6.8/12.9 MB 2.7 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 6.8/12.9 MB 2.7 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.0/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.1/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 7.5/12.9 MB 1.9 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 11.5/12.9 MB 3.0 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.5/12.9 MB 3.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.9 MB 3.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.9 MB 3.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.9/12.9 MB 3.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.9/12.9 MB 3.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.9/12.9 MB 3.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.9/12.9 MB 3.3 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
      "     ---------------------------------------- 0.0/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     -------------------------------------- - 266.2/274.0 kB ? eta -:--:--\n",
      "     ------------------------------------ 274.0/274.0 kB 248.4 kB/s eta 0:00:00\n",
      "Collecting SQLAlchemy<3,>=1.4\n",
      "  Downloading sqlalchemy-2.0.39-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.2/2.1 MB 6.9 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 1.3/2.1 MB 20.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.1/2.1 MB 19.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.1/2.1 MB 13.4 MB/s eta 0:00:00\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.6\n",
      "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "     ---------------------------------------- 0.0/431.7 kB ? eta -:--:--\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  430.1/431.7 kB 28.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ 431.7/431.7 kB 402.5 kB/s eta 0:00:00\n",
      "Collecting langsmith<0.4,>=0.1.17\n",
      "  Downloading langsmith-0.3.15-py3-none-any.whl (343 kB)\n",
      "     ---------------------------------------- 0.0/343.8 kB ? eta -:--:--\n",
      "     ------------------------------------- 343.8/343.8 kB 22.2 MB/s eta 0:00:00\n",
      "Collecting async-timeout<5.0.0,>=4.0.0\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.41\n",
      "  Downloading langchain_core-0.3.45-py3-none-any.whl (415 kB)\n",
      "     ---------------------------------------- 0.0/415.9 kB ? eta -:--:--\n",
      "     ------------------------------------- 415.9/415.9 kB 25.4 MB/s eta 0:00:00\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "     ---------------------------------------- 0.0/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 184.3/193.6 kB ? eta -:--:--\n",
      "     ------------------------------------ 193.6/193.6 kB 175.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\_documente_rares\\desktop\\semester 6\\large language models\\l2\\venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Collecting jinja2\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Collecting sympy==1.13.1\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "     ----------------- ---------------------- 0.7/1.7 MB 23.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.7/1.7 MB 1.5 MB/s eta 0:00:00\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.11.14-cp310-cp310-win_amd64.whl (442 kB)\n",
      "     ---------------------------------------- 0.0/442.9 kB ? eta -:--:--\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/442.9 kB 28.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ 442.9/442.9 kB 401.3 kB/s eta 0:00:00\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0\n",
      "  Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Collecting sentence-transformers>=2.6.0\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "     ---------------------------------------- 0.0/275.9 kB ? eta -:--:--\n",
      "     ------------------------------------- 275.9/275.9 kB 16.6 MB/s eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.5.0-cp310-cp310-win_amd64.whl (51 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.2.0-cp310-cp310-win_amd64.whl (29 kB)\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Using cached yarl-1.18.3-cp310-cp310-win_amd64.whl (90 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "     ---------------------------------------- 0.0/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.8 kB ? eta -:--:--\n",
      "     --------------------------------------- 63.8/63.8 kB 49.7 kB/s eta 0:00:00\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading propcache-0.3.0-cp310-cp310-win_amd64.whl (44 kB)\n",
      "     ---------------------------------------- 0.0/44.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.7/44.7 kB 2.3 MB/s eta 0:00:00\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "     ---------------------------------------- 0.0/50.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 50.9/50.9 kB 1.3 MB/s eta 0:00:00\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14\n",
      "  Downloading orjson-3.10.15-cp310-cp310-win_amd64.whl (133 kB)\n",
      "     ---------------------------------------- 0.0/133.6 kB ? eta -:--:--\n",
      "     -------------------------------------- 133.6/133.6 kB 4.0 MB/s eta 0:00:00\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "     ---------------------------------------- 0.0/54.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 54.5/54.5 kB 2.8 MB/s eta 0:00:00\n",
      "Collecting zstandard<0.24.0,>=0.23.0\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-win_amd64.whl (495 kB)\n",
      "     ---------------------------------------- 0.0/495.5 kB ? eta -:--:--\n",
      "     ------------------------------------- 495.5/495.5 kB 15.7 MB/s eta 0:00:00\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "     ---------------------------------------- 0.0/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  71.7/73.5 kB ? eta -:--:--\n",
      "     --------------------------------------- 73.5/73.5 kB 60.4 kB/s eta 0:00:00\n",
      "Collecting pydantic-core==2.27.2\n",
      "  Using cached pydantic_core-2.27.2-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting python-dotenv>=0.21.0\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "     ---------------------------------------- 0.0/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     -------------------------------------- - 122.9/128.4 kB ? eta -:--:--\n",
      "     ------------------------------------ 128.4/128.4 kB 112.9 kB/s eta 0:00:00\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.15.2-cp310-cp310-win_amd64.whl (41.2 MB)\n",
      "     ---------------------------------------- 0.0/41.2 MB ? eta -:--:--\n",
      "     - -------------------------------------- 1.0/41.2 MB 22.5 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 2.2/41.2 MB 23.1 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 3.7/41.2 MB 26.6 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 5.1/41.2 MB 27.3 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 6.9/41.2 MB 29.5 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 8.2/41.2 MB 30.7 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 9.5/41.2 MB 28.9 MB/s eta 0:00:02\n",
      "     ----------- --------------------------- 11.7/41.2 MB 32.7 MB/s eta 0:00:01\n",
      "     ------------ -------------------------- 13.0/41.2 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------- ------------------------- 14.1/41.2 MB 32.7 MB/s eta 0:00:01\n",
      "     ------------- ------------------------- 14.8/41.2 MB 29.7 MB/s eta 0:00:01\n",
      "     --------------- ----------------------- 16.6/41.2 MB 31.2 MB/s eta 0:00:01\n",
      "     ---------------- ---------------------- 17.7/41.2 MB 29.8 MB/s eta 0:00:01\n",
      "     ----------------- --------------------- 18.3/41.2 MB 28.4 MB/s eta 0:00:01\n",
      "     ----------------- --------------------- 19.0/41.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------ -------------------- 20.0/41.2 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------- ------------------- 20.9/41.2 MB 25.2 MB/s eta 0:00:01\n",
      "     -------------------- ------------------ 21.8/41.2 MB 24.3 MB/s eta 0:00:01\n",
      "     --------------------- ----------------- 23.0/41.2 MB 22.6 MB/s eta 0:00:01\n",
      "     ---------------------- ---------------- 23.5/41.2 MB 21.1 MB/s eta 0:00:01\n",
      "     ----------------------- --------------- 24.6/41.2 MB 21.8 MB/s eta 0:00:01\n",
      "     ------------------------ -------------- 25.7/41.2 MB 21.1 MB/s eta 0:00:01\n",
      "     ------------------------ -------------- 26.4/41.2 MB 20.5 MB/s eta 0:00:01\n",
      "     ------------------------- ------------- 27.0/41.2 MB 18.7 MB/s eta 0:00:01\n",
      "     -------------------------- ------------ 28.0/41.2 MB 19.8 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 28.7/41.2 MB 19.3 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 29.8/41.2 MB 20.5 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 30.5/41.2 MB 19.3 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 31.2/41.2 MB 19.3 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 31.7/41.2 MB 17.7 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 32.2/41.2 MB 17.7 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 32.5/41.2 MB 16.8 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 32.8/41.2 MB 15.6 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 33.3/41.2 MB 15.6 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 33.8/41.2 MB 15.6 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 34.1/41.2 MB 14.5 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 34.6/41.2 MB 13.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 35.6/41.2 MB 13.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 36.2/41.2 MB 13.6 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 36.8/41.2 MB 13.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 37.3/41.2 MB 13.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 38.3/41.2 MB 13.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 39.8/41.2 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  41.2/41.2 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  41.2/41.2 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  41.2/41.2 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  41.2/41.2 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  41.2/41.2 MB 11.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 41.2/41.2 MB 7.9 MB/s eta 0:00:00\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "     ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "     ----- ---------------------------------- 1.5/11.1 MB 30.7 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 2.7/11.1 MB 28.1 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 4.1/11.1 MB 26.5 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 5.0/11.1 MB 26.6 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 6.5/11.1 MB 27.7 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 8.2/11.1 MB 27.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 9.6/11.1 MB 27.8 MB/s eta 0:00:01\n",
      "     --------------------------------------  10.9/11.1 MB 27.3 MB/s eta 0:00:01\n",
      "     --------------------------------------  11.1/11.1 MB 28.4 MB/s eta 0:00:01\n",
      "     --------------------------------------- 11.1/11.1 MB 22.6 MB/s eta 0:00:00\n",
      "Collecting Pillow\n",
      "  Using cached pillow-11.1.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-3.1.1-cp310-cp310-win_amd64.whl (298 kB)\n",
      "     ---------------------------------------- 0.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ---------------------------------------  297.0/298.4 kB ? eta -:--:--\n",
      "     ------------------------------------ 298.4/298.4 kB 267.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in d:\\_documente_rares\\desktop\\semester 6\\large language models\\l2\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Collecting anyio\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "     ---------------------------------------- 0.0/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 92.2/100.9 kB ? eta -:--:--\n",
      "     ------------------------------------- 100.9/100.9 kB 84.1 kB/s eta 0:00:00\n",
      "Collecting httpcore==1.*\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting jsonpointer>=1.9\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "     ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  297.0/301.8 kB 17.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ 301.8/301.8 kB 270.5 kB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\_documente_rares\\desktop\\semester 6\\large language models\\l2\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.2)\n",
      "Collecting sniffio>=1.1\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: mpmath, zstandard, urllib3, tqdm, threadpoolctl, tenacity, sympy, sniffio, safetensors, regex, pyyaml, python-dotenv, pydantic-core, propcache, Pillow, orjson, numpy, networkx, mypy-extensions, multidict, marshmallow, MarkupSafe, jsonpointer, joblib, idna, httpx-sse, h11, greenlet, fsspec, frozenlist, filelock, charset-normalizer, certifi, attrs, async-timeout, annotated-types, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, scipy, requests, pydantic, jsonpatch, jinja2, httpcore, anyio, aiosignal, torch, scikit-learn, requests-toolbelt, pydantic-settings, huggingface-hub, httpx, dataclasses-json, aiohttp, tokenizers, langsmith, transformers, langchain-core, sentence-transformers, langchain-text-splitters, langchain-huggingface, langchain, langchain-community\n",
      "Successfully installed MarkupSafe-3.0.2 Pillow-11.1.0 SQLAlchemy-2.0.39 aiohappyeyeballs-2.6.1 aiohttp-3.11.14 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.9.0 async-timeout-4.0.3 attrs-25.3.0 certifi-2025.1.31 charset-normalizer-3.4.1 dataclasses-json-0.6.7 filelock-3.18.0 frozenlist-1.5.0 fsspec-2025.3.0 greenlet-3.1.1 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 httpx-sse-0.4.0 huggingface-hub-0.29.3 idna-3.10 jinja2-3.1.6 joblib-1.4.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.20 langchain-community-0.3.19 langchain-core-0.3.45 langchain-huggingface-0.1.2 langchain-text-splitters-0.3.6 langsmith-0.3.15 marshmallow-3.26.1 mpmath-1.3.0 multidict-6.2.0 mypy-extensions-1.0.0 networkx-3.4.2 numpy-2.2.4 orjson-3.10.15 propcache-0.3.0 pydantic-2.10.6 pydantic-core-2.27.2 pydantic-settings-2.8.1 python-dotenv-1.0.1 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 requests-toolbelt-1.0.0 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.2 sentence-transformers-3.4.1 sniffio-1.3.1 sympy-1.13.1 tenacity-9.0.0 threadpoolctl-3.6.0 tokenizers-0.21.1 torch-2.6.0 tqdm-4.67.1 transformers-4.49.0 typing-inspect-0.9.0 urllib3-2.3.0 yarl-1.18.3 zstandard-0.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers langchain torch langchain-community langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4156b8a6-585a-4a16-aa00-270270a33f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\_DOCUMENTE_RARES\\Desktop\\Semester 6\\Large Language Models\\L2\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\_DOCUMENTE_RARES\\Desktop\\Semester 6\\Large Language Models\\L2\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Rares\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "\n",
    "if model_name.startswith(\"t5\"):\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "    hf_pipeline = pipeline(\n",
    "        \"text2text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=512,\n",
    "        max_new_tokens=50,\n",
    "        truncation=True\n",
    "    )\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    hf_pipeline = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=512,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=hf_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb2f39eb-228a-4296-a13d-a644ecc1e92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rares\\AppData\\Local\\Temp\\ipykernel_21148\\2625397836.py:4: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  output = llm(prompt)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"How are you? So here's the kicker, just so you're all ready for some real action tonight. Let's make something for our new fans:\\n\\n1. Let's Make the Game\\n\\nA quick look at what we want to do with the game. I know you're not going to agree with that all that it entails, but this is important.\\n\\nA lot of people just want to come out for a game. One thing they're going to want to hear is that.\\n\\nA lot of people want to watch The Avengers. They just want to check out the show, they just like to watch, for a bit, their favorite heroes and villains. It's a great way to relax and to make friends and get a good night's sleep at the same time. That's our goal tonight is just an interesting experiment. We're starting a brand new team, so we're looking for three or four people to help us with that. And we really want to make sure it's a fun place to go, one where you can come and experience the show and make a great time. We've got four or five people already, so that's the number we wanted to target.\\n\\nSo let's find four people, let's find two or three people who are interested in making the game great for this community, the idea is to have a great time. We also have to figure out a way to take away some time when you arrive and see the characters, because it becomes the best thing we can do for the game. We've got lots of people waiting for us this year, especially people who are into the new Marvel movies. We do a little bit of work with those movie stars, that's where we keep taking their voices out.\\n\\n2. Tell your team that\\n\\nSo we are not doing it to win the game. We are going to make it clear what game we're playing. So now we're going to give everyone an opportunity to learn more about each other.\\n\\n3. Take the lead role\\n\\nOkay so we want to help. We want to help our team build an experience that fans want and want us to take away from some of their games. It is not that we're fighting for it and being the leader, we are making progress, we are not fighting for the money.\\n\\nWe take the game seriously and we think it's worth it. We think this is something that we can't all talk about. Maybe if you are a\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Try this for gpt2 and t5-small\n",
    "prompt = \"How are you?\"\n",
    "\n",
    "output = llm(prompt)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ca590c-5615-4936-a60c-306935f0e0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'translate English to French: How are you?\\n\\n[A French-speaking couple] asked me how I lived. There is a lot of trouble. They say their daughters are only going to stay home to raise three grandchildren, and I haven\\'t spoken to my four. They\\'re all going to come home to their kids at six or seven, or it\\'s 10:30, or I\\'ll come home.\\n\\nI\\'ve met the father-and-son or husband-and-wife couples. It\\'s been fun, having that kind of intimacy. And I didn\\'t feel like I needed anyone to help me. When my daughter went in to a hospital, I met her parents. And she has two daughters. Her grandkids are 6 and 8 years old. Her granddaughters are 7 and 6 and 7. So it was really good to have this kind of intimacy with my daughter.\\n\\nMy daughter is now six-years-old. I never asked. I\\'m just trying to be more open with her, so that I can tell her like a brother about the other half. And I mean, this family is so small.\\n\\nThis is why my sisters often ask when I\\'ll be out here in my own house. So when this news comes out, what are my thoughts then? I have this family. We just live together. And maybe after a while they realize that I don\\'t need to travel and there\\'s really nothing. And people forget about that. And then I realize, too, that I don\\'t need to fly there when I need to.\\n\\nNow I understand how this story starts. I remember the day after I saw my child, they sent me to their home around 1 p.m., for an overnight stay and we had two beds. This was it. But then, after we took a nap, I went flying. I went to the hospital. The nurse there said I had a heart attack. She\\'s very, very careful to keep me out of there. And I just walked off-course with my life.\\n\\nShe called the hospital and said, \"What are you doing?\" And I said, \"No worries, I only need a flight to England for this last two days.\"\\n\\nThat was the end of that flight and I\\'ve been able to travel back into the United States where I grew up.\\n\\nSo what\\'s your message to the Muslim population now that Donald Trump has picked a war hero for the White House and is going to'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "template = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"translate English to French: {text}\"\n",
    ")\n",
    "\n",
    "### Try this for gpt2 and t5-small\n",
    "prompt_text = template.format(text=\"How are you?\")\n",
    "\n",
    "response = llm(prompt_text)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90fbf82e-9f50-41b3-b4d2-83b41f2ed33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"You be tasked with takin' the followin' text \\\n",
    "and transformin' it into a joke in the style of {style}. \\\n",
    "Make sure it stays true to the humor and tone of the given style. \\\n",
    "If the text ain't naturally a joke, twist it into somethin' funny! \n",
    "\n",
    "text: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e318633-7238-4f1b-bae6-8e346ad48cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['style', 'text'], input_types={}, partial_variables={}, template=\"You be tasked with takin' the followin' text and transformin' it into a joke in the style of {style}. Make sure it stays true to the humor and tone of the given style. If the text ain't naturally a joke, twist it into somethin' funny! \\n\\ntext: ```{text}```\\n\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate.from_template(template_string)\n",
    "\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c5f95c9-f205-4bd1-b5d6-1cb29b66f93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['style', 'text']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8875a55-bf80-4132-b6ac-b53fd8f61c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_style = \"\"\"pirate\"\"\"\n",
    "\n",
    "prompt_input = \"\"\"Why do programmers prefer dark mode?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "189f60ca-f228-4d7f-8bba-9951e56a90f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'customer_style' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m message \u001b[38;5;241m=\u001b[39m prompt_template\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m----> 2\u001b[0m                     style\u001b[38;5;241m=\u001b[39m\u001b[43mcustomer_style\u001b[49m,\n\u001b[0;32m      3\u001b[0m                     text\u001b[38;5;241m=\u001b[39mcustomer_email)\n\u001b[0;32m      5\u001b[0m response \u001b[38;5;241m=\u001b[39m llm(message)\n\u001b[0;32m      7\u001b[0m response\n",
      "\u001b[1;31mNameError\u001b[0m: name 'customer_style' is not defined"
     ]
    }
   ],
   "source": [
    "message = prompt_template.format(\n",
    "                    style=customer_style,\n",
    "                    text=customer_email)\n",
    "\n",
    "response = llm(message)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e332795-ec3f-4a1b-9026-209c990096c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'why pirates love gold',\n",
       " 'style': 'pirate',\n",
       " 'text': 'Human: Tell a joke about why pirates love gold in the style of pirate.\\n\\nBait: A joke about how one can\\'t tell a joke from a joke.\\n\\nBait: A gag, where it\\'s like they\\'re gonna come around and stop you from coming around so you can finish this one.\\n\\nBait: A gag you had at the end of \"Dance in the Wind,\" where they just said that we had a better chance. Well, you\\'re not going to let that lie and you\\'re not gonna let this lie or what it said or how they did that. And yeah, we were so worried about that. We had to do a little bit of extra work a little bit because we had to stop talking about the last episode.\\n\\nBait: I knew that was going to ruin everyone\\'s night.\\n\\nBait: I didn\\'t know there was going to be the end like so many people were saying. Especially with these characters. They were the heroes, or I don\\'t know what they called them. They were the greats that I want to see next.\\n\\nBait: I really liked \"The Return\" because I had always liked it. It was just really weird to see it from the perspective of another comic book hero. I kind of got bored watching that.\\n\\nBait: So people have always been, like \\'Why you guys care?\\' I mean, you know, they were all heroes or were just just kind of a little too self-absorbed like the characters. I mean, we\\'re not as self-absorbed as we were when Captain Cold comes home and Captain America is there and they all cry and I felt sorry for them. It\\'s just not as I wanted. I thought, I\\'m going to get this character of my for a while, and that\\'s no longer true.\\n\\nBait: I\\'m never worried about that since it\\'s a joke. You know, we\\'re never worried about that sort of thing. That kind of thing makes us kind of laugh a little more and you know? I think that was kind of how we always felt like when we were at some point growing up, and we were always worried about the people behind the wheel or doing something like that.\\n\\nWhen we\\'re younger we don\\'t actually want to be like \\'Who am I on this?\\' So when the show is being done and we have characters telling other people what they should do and something is going to happen'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Tell a joke about {topic} in the style of {style}.\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Example Input\n",
    "topic = \"why pirates love gold\"\n",
    "style = \"pirate\"\n",
    "\n",
    "chain.invoke({\"topic\": topic, \"style\": style})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8f4433-219c-4b42-a317-b93545bc5b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input length of input_ids is 512, but `max_length` is set to 512. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 49\u001b[0m\n\u001b[1;32m     40\u001b[0m overall_chain \u001b[38;5;241m=\u001b[39m SequentialChain(\n\u001b[1;32m     41\u001b[0m     chains\u001b[38;5;241m=\u001b[39m[chain_one, chain_two, chain_three, chain_four],\n\u001b[1;32m     42\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReview\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     43\u001b[0m     output_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnglish_Review\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfollowup_message\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     44\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     47\u001b[0m review \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJe trouve le got mdiocre. La mousse ne tient pas, c\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mest bizarre. J\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124machte les mmes dans le commerce et le got est bien meilleur...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mVieux lot ou contrefaon !?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 49\u001b[0m \u001b[43moverall_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreview\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:181\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     emit_warning()\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain/chains/base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    387\u001b[0m }\n\u001b[0;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain/chains/base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain/chains/base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain/chains/sequential.py:107\u001b[0m, in \u001b[0;36mSequentialChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, chain \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchains):\n\u001b[1;32m    106\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m _run_manager\u001b[38;5;241m.\u001b[39mget_child()\n\u001b[0;32m--> 107\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mknown_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     known_values\u001b[38;5;241m.\u001b[39mupdate(outputs)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {k: known_values[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_variables}\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:181\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     emit_warning()\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain/chains/base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    387\u001b[0m }\n\u001b[0;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain/chains/base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain/chains/base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain/chains/llm.py:126\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    123\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    124\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    125\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 126\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain/chains/llm.py:138\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    136\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[1;32m    146\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[1;32m    147\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain_core/language_models/llms.py:763\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    756\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    757\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    761\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    762\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain_core/language_models/llms.py:966\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    953\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    954\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    964\u001b[0m         )\n\u001b[1;32m    965\u001b[0m     ]\n\u001b[0;32m--> 966\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    969\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain_core/language_models/llms.py:787\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    779\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    786\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 787\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    791\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    794\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    795\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    796\u001b[0m         )\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    798\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain_huggingface/llms/huggingface_pipeline.py:295\u001b[0m, in \u001b[0;36mHuggingFacePipeline._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m batch_prompts \u001b[38;5;241m=\u001b[39m prompts[i : i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Process batch of prompts\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m responses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_prompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpipeline_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# Process each response in the batch\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(responses):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:287\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mlist\u001b[39m(chats), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/pipelines/base.py:1349\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[1;32m   1346\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   1347\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1348\u001b[0m     )\n\u001b[0;32m-> 1349\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(final_iterator)\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m    124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m--> 125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/pipelines/base.py:1275\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1273\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1274\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1275\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1276\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:385\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[1;32m    383\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[0;32m--> 385\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ModelOutput):\n\u001b[1;32m    388\u001b[0m     generated_sequence \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msequences\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:2079\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2076\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_supports_logits_to_keep() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits_to_keep\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[1;32m   2077\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits_to_keep\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2079\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_generated_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_default_max_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2081\u001b[0m \u001b[38;5;66;03m# 7. Prepare the cache.\u001b[39;00m\n\u001b[1;32m   2082\u001b[0m \u001b[38;5;66;03m# - `model_kwargs` may be updated in place with a cache as defined by the parameters in `generation_config`.\u001b[39;00m\n\u001b[1;32m   2083\u001b[0m \u001b[38;5;66;03m# - different models have a different cache name expected by the model (default = \"past_key_values\")\u001b[39;00m\n\u001b[1;32m   2084\u001b[0m \u001b[38;5;66;03m# - `max_length`, prepared above, is used to determine the maximum cache length\u001b[39;00m\n\u001b[1;32m   2085\u001b[0m max_cache_length \u001b[38;5;241m=\u001b[39m generation_config\u001b[38;5;241m.\u001b[39mmax_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1416\u001b[0m, in \u001b[0;36mGenerationMixin._validate_generated_length\u001b[0;34m(self, generation_config, input_ids_length, has_default_max_length)\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids_length \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m generation_config\u001b[38;5;241m.\u001b[39mmax_length:\n\u001b[1;32m   1415\u001b[0m     input_ids_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1417\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput length of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_ids_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_ids_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but `max_length` is set to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This can lead to unexpected behavior. You should consider\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m increasing `max_length` or, better yet, setting `max_new_tokens`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1420\u001b[0m     )\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;66;03m# 2. Min length warnings due to unfeasible parameter combinations\u001b[39;00m\n\u001b[1;32m   1423\u001b[0m min_length_error_suffix \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Generation will stop at the defined maximum length. You should decrease the minimum length and/or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1425\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincrease the maximum length.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1426\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Input length of input_ids is 512, but `max_length` is set to 512. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`."
     ]
    }
   ],
   "source": [
    "## SequentialChain\n",
    "\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\"\n",
    "                    )\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )\n",
    "\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )\n",
    "\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )\n",
    "\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "review = \"Je trouve le got mdiocre. La mousse ne tient pas, c'est bizarre. J'achte les mmes dans le commerce et le got est bien meilleur...\\nVieux lot ou contrefaon !?\"\n",
    "\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379e9e00-5fae-46a2-ad79-376abeb21f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Router Chain\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "\n",
    "## .... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610eebe2-8b6f-493e-a248-6e7b43e28157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
