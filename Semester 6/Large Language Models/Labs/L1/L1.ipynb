{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69dc4c49-db9c-4ac6-b759-86fcd8d46809",
   "metadata": {},
   "source": [
    "# Understanding Large Language Models - Lab 1: Setting Up Your Ecosystem\n",
    "\n",
    "## Introduction\n",
    "### This notebook will guide you through setting up your environment for the course.\n",
    "### We will install the necessary dependencies, download a pre-trained T5 model, and run a simple text-to-text prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd8a391-b7fd-476d-ae2e-ee8b9619f15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.37.2\n",
      "  Obtaining dependency information for transformers==4.37.2 from https://files.pythonhosted.org/packages/85/f6/c5065913119c41ecad148c34e3a861f719e16b89a522287213698da911fc/transformers-4.37.2-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
      "     ---------------------------------------- 0.0/129.4 kB ? eta -:--:--\n",
      "     ----- ------------------------------- 20.5/129.4 kB 330.3 kB/s eta 0:00:01\n",
      "     ----------------- ------------------- 61.4/129.4 kB 656.4 kB/s eta 0:00:01\n",
      "     -------------------------------------- 129.4/129.4 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torch in d:\\anaconda3\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: sentencepiece in d:\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: datasets in d:\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: transformers[torch] in d:\\anaconda3\\lib\\site-packages (4.32.1)\n",
      "Collecting accelerate==0.28.0\n",
      "  Obtaining dependency information for accelerate==0.28.0 from https://files.pythonhosted.org/packages/a0/11/9bfcf765e71a2c84bbf715719ba520aeacb2ad84113f14803ff1947ddf69/accelerate-0.28.0-py3-none-any.whl.metadata\n",
      "  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: filelock in d:\\anaconda3\\lib\\site-packages (from transformers==4.37.2) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in d:\\anaconda3\\lib\\site-packages (from transformers==4.37.2) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda3\\lib\\site-packages (from transformers==4.37.2) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda3\\lib\\site-packages (from transformers==4.37.2) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda3\\lib\\site-packages (from transformers==4.37.2) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda3\\lib\\site-packages (from transformers==4.37.2) (2022.7.9)\n",
      "Requirement already satisfied: requests in d:\\anaconda3\\lib\\site-packages (from transformers==4.37.2) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.37.2)\n",
      "  Obtaining dependency information for tokenizers<0.19,>=0.14 from https://files.pythonhosted.org/packages/c1/02/40725eebedea8175918bd59ab80b2174d6ef3b3ef9ac8ec996e84c38d3ca/tokenizers-0.15.2-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading tokenizers-0.15.2-cp311-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\anaconda3\\lib\\site-packages (from transformers==4.37.2) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\anaconda3\\lib\\site-packages (from transformers==4.37.2) (4.65.0)\n",
      "Requirement already satisfied: psutil in d:\\anaconda3\\lib\\site-packages (from accelerate==0.28.0) (5.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda3\\lib\\site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in d:\\anaconda3\\lib\\site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in d:\\anaconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in d:\\anaconda3\\lib\\site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: xxhash in d:\\anaconda3\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in d:\\anaconda3\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in d:\\anaconda3\\lib\\site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: responses<0.19 in d:\\anaconda3\\lib\\site-packages (from datasets) (0.13.3)\n",
      "INFO: pip is looking at multiple versions of transformers[torch] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting transformers[torch]\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/20/37/1f29af63e9c30156a3ed6ebc2754077016577c094f31de7b2631e5d379eb/transformers-4.49.0-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.0/44.0 kB ? eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/b6/1a/efeecb8d83705f2f4beac98d46f2148c95ecd7babfb31b5c0f1e7017e83d/transformers-4.48.3-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.4/44.4 kB 2.1 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/bd/40/902c95a2a6f5d2d120c940ac4bd1f937c01035af529803c13d65ca33c2d1/transformers-4.48.2-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.4/44.4 kB ? eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/7b/9f/92d3091c44cb19add044064af1bf1345cd35fbb84d32a3690f912800a295/transformers-4.48.1-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.48.1-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.4/44.4 kB 2.1 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/45/d6/a69764e89fc5c2c957aa473881527c8c35521108d553df703e9ba703daeb/transformers-4.48.0-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.4/44.4 kB 2.1 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/f2/3a/8bdab26e09c5a242182b7ba9152e216d5ab4ae2d78c4298eb4872549cd35/transformers-4.47.1-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.1/44.1 kB 2.1 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/d0/a7/7eedcf6a359e1e1eff3bc204ad022485aa5d88c08e1e3e0e0aee8a2e2235/transformers-4.47.0-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.5/43.5 kB 2.1 MB/s eta 0:00:00\n",
      "INFO: pip is still looking at multiple versions of transformers[torch] to determine which version is compatible with other requirements. This could take a while.\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/51/51/b87caa939fedf307496e4dbf412f4b909af3d9ca8b189fc3b65c1faa456f/transformers-4.46.3-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.1/44.1 kB ? eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/ed/ad/c9b96572ab7994e73c64588f8875741823f2daba70e746547fff9a2d9a54/transformers-4.46.2-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.1/44.1 kB ? eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/75/d5/294a09a62bdd88da9a1007a341d4f8fbfc43be520c101e6afb526000e9f4/transformers-4.46.1-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.46.1-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.1/44.1 kB 2.1 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/f9/9d/030cc1b3e88172967e22ee1d012e0d5e0384eb70d2a098d1669d549aea29/transformers-4.45.2-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.4/44.4 kB 2.3 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/17/f2/f01ea29c8eff8e749d96525a17c2d3ec02656cec9a80c20fb3e74dba4b04/transformers-4.45.1-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.45.1-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.4/44.4 kB 2.1 MB/s eta 0:00:00\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/31/6d/09a57274b45a411e6cc62122a032dd4f7cc6fb9e5323d4376ccc1d74bc56/transformers-4.45.0-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.45.0-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.4/44.4 kB 2.3 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/75/35/07c9879163b603f0e464b0f6e6e628a2340cfc7cdc5ca8e7d52d776710d4/transformers-4.44.2-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.7/43.7 kB 2.1 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/47/ab/c42556ba7c5aed687256466d472abb9a1b9cbff5730aa42a884d892e061a/transformers-4.44.1-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.44.1-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.7/43.7 kB 2.2 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/62/c0/810e741a6244c0f004be40ccb96486d072f042eabbd4d7e8aa02b81ca1eb/transformers-4.44.0-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.7/43.7 kB 2.1 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/34/71/af30c8afcdbee5d4ee4b89e366bd7c20ab8b07e7b5acb30e025b81e0ba65/transformers-4.43.4-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.43.4-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.7/43.7 kB 2.2 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/ad/ff/b3e311e58b9c90b149fb957953b228287d7c9fe78df9a3a72e8715c5fc56/transformers-4.43.3-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.43.3-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.7/43.7 kB 2.2 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/13/63/cccd0297770d7096c19c99d4c542f3068a30e73cdfd971a920bfa686cb3a/transformers-4.43.2-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.43.2-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.7/43.7 kB 2.2 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/e3/89/66b0d61558c971dd2c8cbe125a471603fce0a1b8850c2f4d99a07584fca2/transformers-4.43.1-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.43.1-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.7/43.7 kB 1.0 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/23/c6/445ed1d345c215a5ad094cb00359d9697efd5ddb2e5927e32c6852fad666/transformers-4.43.0-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.43.0-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.7/43.7 kB 2.1 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/6a/dc/23c26b7b0bce5aaccf2b767db3e9c4f5ae4331bd47688c1f2ef091b23696/transformers-4.42.4-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.42.4-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.6/43.6 kB 2.1 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/20/5c/244db59e074e80248fdfa60495eeee257e4d97c3df3487df68be30cd60c8/transformers-4.42.3-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.42.3-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.6/43.6 kB ? eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/f4/43/98686ef8254f9448fb46b04adad2dbeab7da786c40c77ad4c59d14dbc6d0/transformers-4.42.2-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.42.2-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.6/43.6 kB 2.2 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/32/a5/ad96309b47ede58104e109689819e24749c7b5bb1d935257240dbefe28dd/transformers-4.42.1-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.42.1-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.6/43.6 kB ? eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/17/4d/ecdde8b38e869033a61b06e8921cf6b6d0f6bb639fcf448c3dbebdc518d1/transformers-4.42.0-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.42.0-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.6/43.6 kB ? eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/d9/b7/98f821d70102e2d38483bbb7013a689d2d646daa4495377bc910374ad727/transformers-4.41.2-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.8/43.8 kB ? eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/79/e1/dcba5ba74392015ceeababf3455138f5875202e66e3316d7ca223bdb7b1c/transformers-4.41.1-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.41.1-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.8/43.8 kB 2.2 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/07/78/c23e1c70b89f361d855a5d0a19b229297f6456961f9a1afa9a69cd5a70c3/transformers-4.41.0-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.41.0-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.8/43.8 kB 2.2 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/05/23/ba02efa28518557e0cfe0ce5c1170000dd7501ed02ac865fc90cbe3daa93/transformers-4.40.2-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n",
      "     ---------------------------------------- 0.0/138.0 kB ? eta -:--:--\n",
      "     -------------------------------------- 138.0/138.0 kB 8.0 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/cf/90/2596ac2ab49c4df6ff1fceaf7f5afb18401ba2f326348ce1a6261a65e7ed/transformers-4.40.1-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.40.1-py3-none-any.whl.metadata (137 kB)\n",
      "     ---------------------------------------- 0.0/138.0 kB ? eta -:--:--\n",
      "     ------------------------------------ - 133.1/138.0 kB 4.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- 138.0/138.0 kB 4.1 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/09/c8/844d5518a6aeb4ffdc0cf0cae65ae13dbe5838306728c5c640b5a6e2a0c9/transformers-4.40.0-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n",
      "     ---------------------------------------- 0.0/137.6 kB ? eta -:--:--\n",
      "     -------------------------------------- 137.6/137.6 kB 8.0 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/15/fc/7b6dd7e1adc0a6407b845ed4be1999e98b6917d0694e57316d140cc85484/transformers-4.39.3-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n",
      "     ---------------------------------------- 0.0/134.8 kB ? eta -:--:--\n",
      "     -------------------------------------- 134.8/134.8 kB 7.8 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/e2/52/02271ef16713abea41bab736dfc2dbee75e5e3512cf7441e233976211ba5/transformers-4.39.2-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.39.2-py3-none-any.whl.metadata (134 kB)\n",
      "     ---------------------------------------- 0.0/134.8 kB ? eta -:--:--\n",
      "     -------------------------------------- 134.8/134.8 kB 3.9 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/0a/fd/280f4385e76f3c1890efc15fa93f7206134fefad6351397e1bfab6d0d0de/transformers-4.39.1-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.39.1-py3-none-any.whl.metadata (134 kB)\n",
      "     ---------------------------------------- 0.0/134.8 kB ? eta -:--:--\n",
      "     -------------------------------------- 134.8/134.8 kB 8.3 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/a4/73/f620d76193954e16db3d5c53a07d956d7b9c800e570758d3bff91906d4a4/transformers-4.39.0-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.39.0-py3-none-any.whl.metadata (134 kB)\n",
      "     ---------------------------------------- 0.0/134.8 kB ? eta -:--:--\n",
      "     -------------------------------------- 134.8/134.8 kB 4.0 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/b6/4d/fbe6d89fde59d8107f0a02816c4ac4542a8f9a85559fdf33c68282affcc1/transformers-4.38.2-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
      "     ---------------------------------------- 0.0/130.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 130.7/130.7 kB 7.5 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/3e/6b/1b589f7b69aaea8193cf5bc91cf97410284aecd97b6312cdb08baedbdffe/transformers-4.38.1-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.38.1-py3-none-any.whl.metadata (131 kB)\n",
      "     ---------------------------------------- 0.0/131.1 kB ? eta -:--:--\n",
      "     -------------------------------------- 131.1/131.1 kB 3.9 MB/s eta 0:00:00\n",
      "  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/91/89/5416dc364c7ef0711c564fd61a69b03d1e40eeb5c506c38e53ba8a969e79/transformers-4.38.0-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.38.0-py3-none-any.whl.metadata (131 kB)\n",
      "     ---------------------------------------- 0.0/131.1 kB ? eta -:--:--\n",
      "     -------------------------------------- 131.1/131.1 kB 3.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in d:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in d:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests->transformers==4.37.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests->transformers==4.37.2) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests->transformers==4.37.2) (2024.2.2)\n",
      "Requirement already satisfied: six in d:\\anaconda3\\lib\\site-packages (from responses<0.19->datasets) (1.16.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers==4.37.2) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "   ---------------------------------------- 0.0/8.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/8.4 MB 5.9 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.6/8.4 MB 5.8 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.8/8.4 MB 5.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.2/8.4 MB 6.1 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.2/8.4 MB 6.1 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.4/8.4 MB 5.1 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.4/8.4 MB 4.8 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.7/8.4 MB 4.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.9/8.4 MB 4.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.1/8.4 MB 4.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.3/8.4 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.6/8.4 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.9/8.4 MB 5.0 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.3/8.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 3.7/8.4 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.2/8.4 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.6/8.4 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.3/8.4 MB 6.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.8/8.4 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.5/8.4 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.3/8.4 MB 7.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.1/8.4 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.4/8.4 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.4/8.4 MB 7.7 MB/s eta 0:00:00\n",
      "Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
      "   ---------------------------------------- 0.0/290.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 290.1/290.1 kB 18.7 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.15.2-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.6/2.2 MB 12.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.7/2.2 MB 7.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 9.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.0/2.2 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 10.8 MB/s eta 0:00:00\n",
      "Installing collected packages: tokenizers, accelerate, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.2\n",
      "    Uninstalling tokenizers-0.13.2:\n",
      "      Successfully uninstalled tokenizers-0.13.2\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 1.4.0\n",
      "    Uninstalling accelerate-1.4.0:\n",
      "      Successfully uninstalled accelerate-1.4.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.32.1\n",
      "    Uninstalling transformers-4.32.1:\n",
      "      Successfully uninstalled transformers-4.32.1\n",
      "Successfully installed accelerate-0.28.0 tokenizers-0.15.2 transformers-4.37.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.37.2 torch sentencepiece datasets transformers[torch] accelerate==0.28.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee8aa32e-c5f7-45e6-9631-51b220fdeaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1226916ac0c4872b727c971f9c58a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Rares\\.cache\\huggingface\\hub\\models--t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[13959,  1566,    12,  2379,    10,   571,    33,    25,    58,     1]])\n",
      "translate English to French: How are you?</s>\n",
      "tensor([[   0, 5257,    3, 6738,   18, 3249,   58,    1]])\n",
      "<pad> Comment êtes-vous?</s>\n",
      "Input: translate English to French: How are you?\n",
      "Output: Comment êtes-vous?\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "def generate_text(input_text, max_length=50):\n",
    "    \n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    ### PRINT OUT input_ids\n",
    "    print(input_ids)\n",
    "    print(tokenizer.decode(input_ids[0]))\n",
    "    \n",
    "    output_ids = model.generate(input_ids, max_length=max_length)\n",
    "\n",
    "    ### PRINT OUT output_ids\n",
    "    print(output_ids)\n",
    "    print(tokenizer.decode(output_ids[0]))\n",
    "    \n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "example_input = \"translate English to French: How are you?\"\n",
    "output_text = generate_text(example_input)\n",
    "\n",
    "print(\"Input:\", example_input)\n",
    "print(\"Output:\", output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "642c35b9-90ad-4045-a10e-8e8eab0d7046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[571,  33,  25,  58,   1]])\n",
      "How are you?</s>\n",
      "tensor([[    0,  2739, 15840,   146,    58,     1]])\n",
      "<pad> Wie bist du?</s>\n",
      "Wie bist du?\n",
      "tensor([[363,  19,  39, 564,  58,   1]])\n",
      "What is your name?</s>\n",
      "tensor([[   0, 2751,   19,   39,  564,   58,    1]])\n",
      "<pad> Was is your name?</s>\n",
      "Was is your name?\n",
      "tensor([[ 2840,    19,     8, 13012,  2062,    58,     1]])\n",
      "Where is the nearest restaurant?</s>\n",
      "tensor([[   0, 3488,  229,  211, 6233,    3,   58,    1]])\n",
      "<pad> Wo ist das Restaurant?</s>\n",
      "Wo ist das Restaurant?\n",
      "tensor([[  27,  333, 1036,  126,  378,    5,    1]])\n",
      "I love learning new things.</s>\n",
      "tensor([[    0,  1674, 23803,     3,    15,     7,     6,  2802, 13367,   170,\n",
      "         14891,   170, 14891,     5,     1]])\n",
      "<pad> Ich liebe es, neue Dinge zu lernen zu lernen.</s>\n",
      "Ich liebe es, neue Dinge zu lernen zu lernen.\n",
      "tensor([[100,  19,   3,   9, 786, 239,   5,   1]])\n",
      "This is a beautiful day.</s>\n",
      "tensor([[    0,   644,   229,   266, 11878,  1743,     5,     1]])\n",
      "<pad> Das ist eine schöne Zeit.</s>\n",
      "Das ist eine schöne Zeit.\n"
     ]
    }
   ],
   "source": [
    "### Try at least 5 other example inputs\n",
    "### Example 1: \"How are you?\"\n",
    "### Example 2: \"What is your name?\"\n",
    "### Example 3: \"Where is the nearest restaurant?\"\n",
    "### Example 4: \"I love learning new things.\"\n",
    "### Example 5: \"This is a beautiful day.\"\n",
    "\n",
    "example_input = \"How are you?\"\n",
    "output_text = generate_text(example_input)\n",
    "print(output_text)\n",
    "\n",
    "example_input = \"What is your name?\"\n",
    "output_text = generate_text(example_input)\n",
    "print(output_text)\n",
    "\n",
    "example_input = \"Where is the nearest restaurant?\"\n",
    "output_text = generate_text(example_input)\n",
    "print(output_text)\n",
    "\n",
    "example_input = \"I love learning new things.\"\n",
    "output_text = generate_text(example_input)\n",
    "print(output_text)\n",
    "\n",
    "example_input = \"This is a beautiful day.\"\n",
    "output_text = generate_text(example_input)\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e8e32-e518-4366-a807-c09e76faecbb",
   "metadata": {},
   "source": [
    "# T5 and the Prefix + Input Structure\n",
    "\n",
    "T5 (Text-to-Text Transfer Transformer) is explicitly trained to follow a **prefix + input** format, guiding it to perform the correct NLP task.\n",
    "\n",
    "## Why Prefixes Matter\n",
    "T5 was trained using structured prompts like:\n",
    "- `translate English to French: How are you?` → `Comment allez-vous?`\n",
    "- `summarize: The Eiffel Tower is in Paris.` → `Eiffel Tower is in Paris.`\n",
    "- `question: Who discovered gravity? context: Isaac Newton discovered gravity.` → `Isaac Newton`\n",
    "- `sentiment: I love this movie!` → `positive`\n",
    "\n",
    "## Without a Prefix?\n",
    "❌ `How are you?` → (Unpredictable output)  \n",
    "✅ `translate English to French: How are you?` → `Comment allez-vous?`\n",
    "\n",
    "## Custom Prefixes\n",
    "Fine-tune T5 with your own prefixes:\n",
    "- `explain: What is...`\n",
    "- `medical diagnosis: Patient has high fever...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "973e9772-3cea-4585-b29c-da2da22392dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 26:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.004157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.234400</td>\n",
       "      <td>0.000281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete! Model saved to ./t5-custom-response\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "csv_filename = \"explain_dataset.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_filename)\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = examples[\"Input\"]\n",
    "    targets = examples[\"Response\"]\n",
    "    \n",
    "    model_inputs = tokenizer(inputs, max_length=64, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    labels = tokenizer(targets, max_length=64, truncation=True, padding=\"max_length\").input_ids\n",
    "\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    \n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "dataset_split = tokenized_dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "train_dataset = dataset_split[\"train\"]\n",
    "eval_dataset = dataset_split[\"test\"]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./t5-fine-tuned\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./t5-custom-response\")\n",
    "tokenizer.save_pretrained(\"./t5-custom-response\")\n",
    "\n",
    "print(\"Fine-tuning complete! Model saved to ./t5-custom-response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94b21356-cd22-457f-ac52-4240973e9bce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Output:\n",
      "Warum ist die Frage, wie machmach learning?\n",
      "\n",
      "\n",
      "\n",
      "Fine-Tuned Model Output:\n",
      "Machine learning is a subset of AI that enables systems to learn from data and improve without explicit programming.\n"
     ]
    }
   ],
   "source": [
    "original_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "fine_tuned_model = T5ForConditionalGeneration.from_pretrained(\"./t5-custom-response\")\n",
    "\n",
    "def generate_response(model, input_text):\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "    output_ids = model.generate(input_ids, max_length=64)\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "test_question = \"explain: What is machine learning?\"\n",
    "\n",
    "original_output = generate_response(original_model, test_question)\n",
    "fine_tuned_output = generate_response(fine_tuned_model, test_question)\n",
    "\n",
    "print(\"Original Model Output:\")\n",
    "print(original_output)\n",
    "print(\"\\n\\n\\nFine-Tuned Model Output:\")\n",
    "print(fine_tuned_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
